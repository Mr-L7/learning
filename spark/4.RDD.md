Resilient Distributed Dataset
-----------------------------

## RDD

> A Resilient Distributed Dataset (RDD), the basic abstraction in Spark. Represents an immutable, partitioned collection of elements that can be operated on in parallel.

> Internally, each RDD is characterized by five main properties:

>- A list of partitions
>- A function for computing each split
>- A list of dependencies on other RDDs
>- Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)
>- Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)

> All of the **scheduling** and **execution** in Spark is done based on these methods, allowing each RDD to implement its own way of computing itself.

## RDD的设计初衷
先抛开RDD是什么、RDD里面包含了什么这些问题，我们先来理解一下RDD的设计初衷。

Map Reduce类的运算框架的逻辑，说白了就是如何高可扩展、高容错的利用大量的机器来做并行化的处理。所以在这些框架中，很大的工作量是如何来保证容错性、如何来保证并发性和扩展性。比如Hadoop，它就通过将运算结果存储到HDFS中，通过在HDFS中保存多份结果来保证系统的容错性。至于并发性，则主要是通过如何做好任务调度来完成。但是，Hadoop这样框架的一个问题是性能不高，系统相对较慢，这里有一篇关于[《传统的MapReduce框架慢在那里》](http://jerryshao.me/architecture/2013/04/15/%E4%BC%A0%E7%BB%9F%E7%9A%84MapReduce%E6%A1%86%E6%9E%B6%E6%85%A2%E5%9C%A8%E5%93%AA%E9%87%8C/)的文章，可以看看，很重要的一个原因是MapReduce框架中，`map`以及`reduce`的操作输入和输出通常是HDFS，所以每个过程都会涉及到分布式文件系统的读写过程，这造成这些框架的运算性能会受到分布式文件系统性能的影响。

RDD的设计初衷则是，考虑如何通过避免或减少对分布式文件系统的依赖，通过内存计算来提高运算性能。所以Spark一个很关键的地方就是如何利用内存。但是利用内存进行并行计算和通过分布式文件系统作为交换数据的中介不同，内存并行计算存在两个问题：
* 如何并行得管理内存中的数据集以便进行分布式计算
* 如何保证内存计算的可靠性

### RDD的可靠性设计
可靠性主要考虑的是数据没了，系统怎么把数据给恢复出来。而内存作为一种易失型的存储介质，一旦断电或者什么的，里面的数据就没了。所以如何保证内存中数据的可靠性呢？在RDD中，作者引入了`Lineage`的概念。什么是`Lineage`呢？字面上是*血统、家系、世袭*的意思。所以，就比较好理解了，也就是说RDD是怎么得来的一个记录，就如同你在你们家族里面是怎么来的一样，你爸爸的爸爸的爸爸的爸爸的爸爸的爸爸的爸爸的爸爸，生了你爸爸的爸爸的爸爸的爸爸的爸爸的爸爸的爸爸，生了....，最后你爸爸生了你一样。（纸包鸡什么的最好吃了。）虽然你爸爸的爸爸的爸爸的爸爸的爸爸的爸爸的爸爸的爸爸早就已经不在了，但是只要有这张家族图谱，你就可以知道你是怎么来的。RDD的`Lineage`也就是这个意思，RDD需要有一种方式，在数据不存在的时候，如何把它恢复出来。所以在RDD里面就有咱们上面提到的`dependencies`的概念存在，也就是说`RDD`要记住谁生了它。

Spark面向的是大数据，数据有那么多，要以多大的粒度来记住这么多的数据的继承关系呢？如果太细，比如以数据块来记录，那么通常需要以大量的内存在记录这些转换关系，这本身将会是很大的开销。所以，Spark的策略是以较大的粒度来记录这些关系，这个粒度就是RDD。大数据处理者们，Spark只能帮咱们到这里了。所以Spark不太适合处理一些细粒度的需求。比如需要对数据进行大量不一样的操作。

### RDD的Partion
Spark以RDD来管理分区数据，这个粒度是很大的。这么大的数据通常很难在一台机器上处理，这里便涉及到了如何对数据进行分区。所以在RDD里面需要有如何对数据进行分区的分区方法，如`partitioner`，以及`partitions`，除此之外，还需要有一个用来计算每个partition（即RDD源代码中的`split`）的函数`compute`。另外，为了考虑locality，RDD还提供了计算的优先位置选择的接口`getPreferredLocations`方法。

## RDD.scala的代码结构
RDD相关的代码主要分布在`package org.apache.spark.rdd`中，包括RDD基类`RDD.scala`; 一些列的派生RDD类，如`MappedRDD` `FilteredRDD`等等; 某些RDD类特有的方法，如`DoubleRDDFunctions` `OrderedRDDFunctions` `PairRDDFunctions` `SequenceFileRDDFunctions`; 以及一些特殊的RDD Actions (`AsyncRDDActions.scala`)和用于Checkpoint的(`RDDCheckpointData.scala`)类。

`package org.apache.spark.rdd`的组织方式大致就是按照以上所描述的结构来划分的，rdd包的结构简化图如下：
![package org.apache.spark.rdd](./img/RDD.jpg)

